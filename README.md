# Generative-AI-Model-From-Scratch
A Machine Learning model is used to make predictions based on historical data. Similarly, a Generative AI model creates new original data by learning from the historical data.
# Introduction
Building a generative AI model from scratch involves a dual-network setup consisting of a generator and a discriminator, unlike a typical machine learning model that usually involves a single predictive model. In generative AI, the generator creates new data samples from random noise, while the discriminator evaluates these samples against real data to classify them as real or fake. The two networks are trained in tandem through an adversarial process where the generator aims to improve its ability to produce realistic outputs, and the discriminator enhances its accuracy in distinguishing between genuine and generated data. Generative Adversarial Networks (GANs) consist of two neural networks:
1. Generator: Generates new data samples.
2. Discriminator: Evaluates whether a given data sample is real (from the training data) or fake (generated by the generator).
<br>
<br>
The two networks are trained together in a zero-sum game: the generator tries to fool the discriminator, while the discriminator aims to accurately distinguish real from fake data.A GAN consists of the following key components:
1. Noise Vector: A random input vector fed into the generator.
2. Generator: A neural network that transforms the noise vector into a data sample.
3. Discriminator: A neural network that classifies input data as real or fake.

# Feature
we will use the MNIST dataset for building a generative AI model from scratch because of these three reasons:
1. the data is large enough to create a generative AI model
2. loading the data is easy
3. training a generative AI model on this data will be possible for you, given the computational power of Google Colab (that most beginners use as students)

# Conclusion
we are defining and training a Generative Adversarial Network by combining a generator and a discriminator into a single model. The gan_input represents the random noise fed into the generator, which produces a generated_image. This image is then passed to the discriminator, which outputs a probability (gan_output) indicating whether the image is real or fake. The discriminator’s weights are set to non-trainable during this process to ensure that only the generator learns from the adversarial feedback. The GAN is trained using the function train_gan, where the discriminator first learns to distinguish between real images and fake images generated by the generator, and then the generator is updated to produce more convincing fake images. The loss functions guide this adversarial process, where the generator aims to minimize the discriminator’s ability to detect fakes, which results in progressively more realistic generated images. The save_images function periodically saves these generated images to visualize the training progress.
<br>
<br>
The first image represents images of the early outputs. Initially, the images appear as random noise without any discernible patterns. It represents that the generator wasn’t able to learn how to produce meaningful outputs during this training phase. The second image represents images from the intermediate output. It shows that as training progresses, the generator starts producing outputs that begin to resemble the structure of handwritten digits. Although some images still appear noisy or indistinct, there’s a noticeable shift towards more defined shapes and features. During these stages, the generator and discriminator are in a competitive phase where both networks are improving. The generator tries to create more realistic images, while the discriminator enhances its ability to distinguish between real and generated samples. The third image represents images from the later stages of the output generated by the model. The images show a significant improvement, with many outputs clearly resembling real MNIST digits. The details of the digits are more defined, and the shapes are more accurate, which reflects the generator’s increased capability to capture the distribution of the training data.
<br>
<br>
So, in generative AI, the generator creates new data samples from random noise, while the discriminator evaluates these samples against real data to classify them as real or fake. The two networks are trained in tandem through an adversarial process where the generator aims to improve its ability to produce realistic outputs, and the discriminator enhances its accuracy in distinguishing between genuine and generated data.

# Contributing
If you are interested in contributing to the project, please create a fork of the repository and submit a pull request. All contributions are welcome and appreciated.
